{"cells":[{"cell_type":"code","source":["!pip install timed_count\n","!pip install pymongo[srv]"],"metadata":{"id":"yDViOyjWGKT2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"913fM21TGBhs","executionInfo":{"status":"ok","timestamp":1703819011665,"user_tz":-420,"elapsed":1870,"user":{"displayName":"R. Abdullah Hammami","userId":"02069717998167369570"}}},"outputs":[],"source":["import pandas as pd\n","import requests\n","from bs4 import BeautifulSoup\n","from threading import Thread\n","from timed_count import timed_count\n","\n","from pprint import pprint\n","\n","import datetime as dt\n","from tzlocal import get_localzone\n","\n","import random\n","import time\n","import os"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"6epGAUu6UOh9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pymongo\n","from pymongo import MongoClient\n","\n","user = 'alfalimbany'\n","sandi = 'BangRaf454647'\n","# uri (uniform resource identifier) defines the connection parameters\n","\n","uri = 'mongodb+srv://'+ user +':'+ sandi +'@kuliah.uohhxud.mongodb.net/?retryWrites=true&w=majority'\n","# start client to connect to MongoDB server\n","client = MongoClient(uri)"],"metadata":{"id":"rADCdJ6gWo4H","executionInfo":{"status":"ok","timestamp":1703820166172,"user_tz":-420,"elapsed":303,"user":{"displayName":"R. Abdullah Hammami","userId":"02069717998167369570"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["client.stats                                # .stats  show details about the client"],"metadata":{"id":"dr6XVjUlV8Ez"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Hbk5nElsn45D","executionInfo":{"status":"ok","timestamp":1703820169246,"user_tz":-420,"elapsed":1,"user":{"displayName":"R. Abdullah Hammami","userId":"02069717998167369570"}}},"outputs":[],"source":["StackOverflow_db = client['StackOverflow_db']\n","\n","info_collection = StackOverflow_db['info_collection']\n","\n","comment_collection = StackOverflow_db['comment_collection']"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"wMsSGCTGGBh1","executionInfo":{"status":"ok","timestamp":1703820171714,"user_tz":-420,"elapsed":288,"user":{"displayName":"R. Abdullah Hammami","userId":"02069717998167369570"}}},"outputs":[],"source":["target = 'StackOverflow'"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"R_nwiybIGBh2","executionInfo":{"status":"ok","timestamp":1703820173148,"user_tz":-420,"elapsed":2,"user":{"displayName":"R. Abdullah Hammami","userId":"02069717998167369570"}}},"outputs":[],"source":["def scrap(data):\n","    allData = []\n","    start = dt.datetime.now(tz=get_localzone())\n","    fmt = \"%m/%d/%y - %T %p\"\n","    # Print starting output for app\n","    print('---'*20)\n","    print('---'*20)\n","    print(f'***** {target} started at {start.strftime(fmt)}')\n","    print()\n","    # looping data to scrap more details\n","    for item in data:\n","        # define target scrap based on question id\n","        url = 'https://stackoverflow.com/questions/' + str(item['question_id'])\n","        # make request to api\n","        req = requests.get(url)\n","        # parsing request with Beautifulsoup html parser\n","        soup = BeautifulSoup(req.text, 'html.parser')\n","        # defining variables\n","        question_id = str(item['question_id'])\n","        title = soup.find('a', {'class': 'question-hyperlink'}).text.strip() # type: ignore\n","        content = soup.find('div', {'class': 'js-post-body'}).text.strip()  # type: ignore\n","        post_tag = str(item['tags'])[1:-1]\n","        if str(item['owner']['user_id']) != '':\n","          user_id = str(item['owner']['user_id'])\n","        else:\n","          user_id = '-'\n","        question_stamp = soup.time.attrs # type: ignore\n","        # Array untuk menyimpan hasil scraping\n","        answers_data = []\n","\n","        # Find all answer divs\n","        answer_divs = soup.find_all('div', {'class': 'answer'})\n","\n","        # Extract information from each answer\n","        for i, answer_div in enumerate(answer_divs):\n","            if i < 3:  # Adjust the number to the desired number of answers to display\n","                # Extract user_id\n","                user_id_tag = answer_div.find('div', {'itemprop': 'author'}).find('a')\n","                answer_user_id = user_id_tag['href'].split('/')[-2] if user_id_tag else \"Kosong\"\n","                # Extract answer text\n","                answer_text_tag = answer_div.find('div', {'class': 's-prose'})\n","                answer_text = answer_text_tag.text.strip() if answer_text_tag else \"Kosong\"\n","\n","                # Extract upvote count\n","                upvote_count_tag = answer_div.find('div', {'class': 'js-vote-count'})\n","                upvote_count = upvote_count_tag.text.strip() if upvote_count_tag else \"0\"\n","\n","                # Extract answer time based on user-action-time\n","                answer_time_tag = answer_div.find('div', {'class': 'user-action-time'}).find('span', {'class': 'relativetime'})\n","                answer_time = answer_time_tag['title'].replace('Z', '') if answer_time_tag else \"Kosong\"\n","\n","                # Extract comments for each answer\n","                comments = []\n","                comments_list = answer_div.find('ul', {'class': 'comments-list'})\n","                if comments_list:\n","                    for comment_div in comments_list.find_all('li', {'class': 'comment'}):\n","                        # Extract comment text\n","                        comment_text_tag = comment_div.find('span', {'class': 'comment-copy'})\n","                        comment_text = comment_text_tag.text.strip() if comment_text_tag else \"Kosong\"\n","\n","                        # Extract comment user_id\n","                        comment_user_id_tag = comment_div.find('a', {'class': 'comment-user'})\n","                        comment_user_id = comment_user_id_tag['href'].split('/')[-2] if comment_user_id_tag else \"Kosong\"\n","\n","                        # Extract comment date\n","                        comment_date_tag = comment_div.find('span', {'class': 'relativetime-clean'})\n","                        comment_date = comment_date_tag['title'].replace('Z, License: CC BY-SA ', '').replace('3.0', '').replace('4.0', '').replace('5.0', '') if comment_date_tag else \"Kosong\"\n","\n","                        comments.append({'comment_text': comment_text, 'comment_user_id': comment_user_id, 'comment_date': comment_date})\n","\n","                # Menyimpan data jawaban ke dalam array\n","                answer_data = {\n","                    'answer_user_id': answer_user_id,\n","                    'answer_text': answer_text,\n","                    'answer_time': answer_time,\n","                    'upvote_count': upvote_count,\n","                    'comments': comments\n","                }\n","                answers_data.append(answer_data)\n","        # appending item to array\n","        allData.append({'question_id': question_id,'title': title, 'content': content, 'post_tag': post_tag, 'user_id': user_id, 'question_stamp': question_stamp['datetime'], 'answers': answers_data})\n","        time.sleep(1.0)\n","    #Save into MongoDB\n","    comment_collection.insert_many(allData)\n","    # transform array to Pandas DataFrame\n","    check_out = pd.DataFrame(allData)\n","    # output path for storing data\n","    output_path = '/content/drive/MyDrive/Kuliah/RPL/scraper/' + target + '.csv'\n","    # storing data into csv format\n","    check_out.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n","    allData.clear()\n","    end = dt.datetime.now(tz=get_localzone())\n","    print(f\"\"\"\n","        Successfully inserted {len(check_out)} {target} Questions into collection\n","        at {end.strftime(fmt)}.\\n\n","        \"\"\")\n","    print(f'Time elapsed for {target}: {end-start}')\n","    print('---'*20)\n","    print('---'*20)\n","    print('\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q7Hok1VZGBh3"},"outputs":[],"source":["question_count = 10\n","for count in timed_count(120):\n","    api = requests.get(\n","        'https://api.stackexchange.com/2.3/search/advanced?pagesize='+\n","        str(question_count) +'&order=desc&sort=activity&site=stackoverflow').json()\n","    data = api['items']\n","    scrap(data)"]},{"cell_type":"code","source":["api = requests.get(\n","        'https://api.stackexchange.com/2.3/search/advanced?pagesize=2&order=desc&sort=activity&site=stackoverflow').json()\n","data = api['items']\n","scrap(data)"],"metadata":{"id":"MSqoU-FXI1HE"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"2d681002bfa98c22e3a55bd09cef3381f6316e5c0f3421472a2863e693739461"}},"colab":{"provenance":[{"file_id":"https://github.com/Bang-Raf/Stack-Overflow-Scraper/blob/main/ScraperSO.ipynb","timestamp":1700207106625}]},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}